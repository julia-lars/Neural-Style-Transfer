import numpy as np
import cv2
import os
import vgg
import PIL.Image
import tensorflow as tf

# ==========================================
# 0. å…¨å±€é…ç½®ä¸è¾…åŠ©å‡½æ•°
# ==========================================

# é£æ ¼å›¾åˆ—è¡¨ (è¯·ç¡®ä¿è¿™äº›æ–‡ä»¶éƒ½åœ¨ data/style-images/ ä¸‹)
STYLE_IMAGES_LIST = ['s1.jpg', 's2.jpg', 's3.png', 's4.png', 's5.png']

# å›ºå®šçš„å†…å®¹å›¾å’ŒMaskè·¯å¾„
CONTENT_PATH = "data/content-images/c1.jpg"
MASK_PATH = "data/masks/mask_cat.png"

# æ€»è¾“å‡ºå¤§æ–‡ä»¶å¤¹
MAIN_OUTPUT_DIR = "data/batch_results_dual"

if not os.path.exists(MAIN_OUTPUT_DIR):
    os.makedirs(MAIN_OUTPUT_DIR)

def get_color_stats(img, mask):
    """è®¡ç®—å›¾ç‰‡åœ¨ mask åŒºåŸŸå†…çš„å‡å€¼å’Œæ ‡å‡†å·®"""
    valid_pixels = img[mask > 128]
    if len(valid_pixels) == 0:
        return np.zeros(3), np.zeros(3)
    mean = np.mean(valid_pixels, axis=0)
    std = np.std(valid_pixels, axis=0)
    return mean, std

def apply_color_transfer(style_img, mean_target, std_target):
    """LAB é¢œè‰²è¿ç§»"""
    style_img = cv2.cvtColor(style_img, cv2.COLOR_BGR2LAB).astype(float)
    mean_style = np.mean(style_img, axis=(0,1))
    std_style = np.std(style_img, axis=(0,1))
    std_style[std_style == 0] = 1e-5
    
    for i in range(3):
        style_img[:,:,i] = (style_img[:,:,i] - mean_style[i]) + mean_target[i]
        
    style_img = np.clip(style_img, 0, 255).astype(np.uint8)
    return cv2.cvtColor(style_img, cv2.COLOR_LAB2BGR)

# ==========================================
# æ ¸å¿ƒä»»åŠ¡å‡½æ•°ï¼šå°è£…äº†åŸæœ¬çš„æ‰€æœ‰é€»è¾‘
# ==========================================
def run_style_transfer(style_filename):
    print(f"\n{'='*40}")
    print(f"æ­£åœ¨å¤„ç†é£æ ¼å›¾: {style_filename}")
    print(f"{'='*40}")

    # 1. å‡†å¤‡å½“å‰ä»»åŠ¡çš„è¾“å‡ºç›®å½•
    style_name_no_ext = os.path.splitext(style_filename)[0] # å»æ‰åç¼€ï¼Œå¦‚ s1
    current_output_dir = os.path.join(MAIN_OUTPUT_DIR, style_name_no_ext)
    
    if not os.path.exists(current_output_dir):
        os.makedirs(current_output_dir)

    style_path = os.path.join("data/style-images", style_filename)

    # ================= é¢„å¤„ç†ï¼šç”ŸæˆåŒé£æ ¼å›¾ =================
    content = cv2.imread(CONTENT_PATH)
    style = cv2.imread(style_path)
    mask = cv2.imread(MASK_PATH, 0)

    if content is None or style is None or mask is None:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {style_filename}ï¼Œè·³è¿‡...")
        return

    # ç¼©æ”¾ mask
    mask = cv2.resize(mask, (content.shape[1], content.shape[0]), interpolation=cv2.INTER_NEAREST)
    content_lab = cv2.cvtColor(content, cv2.COLOR_BGR2LAB).astype(float)

    # ç»Ÿè®¡ä¿¡æ¯
    mean_bg, std_bg = get_color_stats(content_lab, mask) # mask>128 (ç™½) -> èƒŒæ™¯
    mask_fg_cv = cv2.bitwise_not(mask)
    mean_fg, std_fg = get_color_stats(content_lab, mask_fg_cv) # mask_fg>128 -> å‰æ™¯

    # ç”Ÿæˆå¹¶ä¿å­˜ä¸´æ—¶é£æ ¼å›¾ (å­˜åœ¨å„è‡ªçš„æ–‡ä»¶å¤¹é‡Œ)
    style_fg = apply_color_transfer(style.copy(), mean_fg, std_fg)
    style_fg_path = os.path.join(current_output_dir, "style_fg.jpg")
    cv2.imwrite(style_fg_path, style_fg)

    style_bg = apply_color_transfer(style.copy(), mean_bg, std_bg)
    style_bg_path = os.path.join(current_output_dir, "style_bg.jpg")
    cv2.imwrite(style_bg_path, style_bg)

    # ================= TensorFlow å›¾æ„å»º =================
    # é‡è¦ï¼šæ¯æ¬¡å¾ªç¯å¿…é¡»é‡ç½® TF å›¾ï¼Œå¦åˆ™èŠ‚ç‚¹ä¼šç´¯ç§¯å¯¼è‡´æ˜¾å­˜çˆ†ç‚¸
    tf.reset_default_graph() 

    # æƒé‡é…ç½® (ä¿æŒä½ çš„å‚æ•°)
    BG_LAPLACE_WEIGHT = 0.05 
    BG_CONTENT_WEIGHT = 0.1
    BG_STYLE_RATIO = 1
    FG_STYLE_RATIO = 0.2
    STYLE_LAYER_WEIGHTS = [20, 20, 20, 20, 5000]
    
    # å®šä¹‰ç½‘ç»œæ“ä½œè¾…åŠ©å‡½æ•°
    def make_kernel(a):
        a = np.asarray(a)
        a = a.reshape(list(a.shape) + [1, 1])
        return tf.constant(a, dtype=1)

    def simple_conv(x, k):
        num_channels = int(x.get_shape()[-1])
        k_tiled = tf.tile(k, [1, 1, num_channels, 1])
        y = tf.nn.depthwise_conv2d(x, k_tiled, strides=[1, 1, 1, 1], padding='SAME')
        return y

    def laplace(x):
        laplace_k = make_kernel([[0.5, 1.0, 0.5], [1.0, -6., 1.0], [0.5, 1.0, 0.5]])
        return simple_conv(x, laplace_k)

    def compute_masked_gram(feature_map, mask_resized):
        masked_features = feature_map * mask_resized
        num_channels = tf.cast(tf.shape(feature_map)[3], tf.float32)
        valid_pixels = tf.reduce_sum(mask_resized) + 1e-5
        flat = tf.reshape(masked_features, [-1, tf.shape(feature_map)[3]])
        gram = tf.matmul(flat, flat, transpose_a=True) / (2.0 * num_channels * valid_pixels)
        return gram

    def compute_global_gram(feature_map):
        num_channels = tf.cast(tf.shape(feature_map)[3], tf.float32)
        num_pixels = tf.cast(tf.reduce_prod(tf.shape(feature_map)[1:3]), tf.float32)
        flat = tf.reshape(feature_map, [-1, tf.shape(feature_map)[3]])
        gram = tf.matmul(flat, flat, transpose_a=True) / (2.0 * num_channels * num_pixels)
        return gram

    # åŠ è½½æ•°æ®
    model = vgg.Vgg19()
    content_img_np = np.asarray(PIL.Image.open(CONTENT_PATH).convert('RGB'), dtype=float)
    img_width = content_img_np.shape[0]
    img_height = content_img_np.shape[1]

    style_fg_np = np.asarray(PIL.Image.open(style_fg_path).convert('RGB'))
    style_fg_resized = tf.image.resize_images(style_fg_np, size=[img_width, img_height])

    style_bg_np = np.asarray(PIL.Image.open(style_bg_path).convert('RGB'))
    style_bg_resized = tf.image.resize_images(style_bg_np, size=[img_width, img_height])

    mask_np_src = np.asarray(PIL.Image.open(MASK_PATH).convert('L').resize((img_height, img_width)), dtype=float) / 255.0
    mask_tensor = tf.reshape(tf.constant(mask_np_src, dtype=tf.float32), [1, img_width, img_height, 1])
    
    # Maskå®šä¹‰
    mask_bg = mask_tensor 
    mask_fg = 1 - mask_tensor

    # æ··åˆåˆå§‹åŒ–é€»è¾‘
    b = np.zeros(shape=[1, img_width, img_height, 3])
    b[0] = content_img_np
    
    noise_np = np.random.normal(loc=128.0, scale=30.0, size=(1, img_width, img_height, 3)).astype(np.float32)
    noise_np = np.clip(noise_np, 0, 255)
    
    mask_broadcast = mask_np_src.reshape(1, img_width, img_height, 1)
    
    # æ··åˆåˆå§‹åŒ–ï¼šMask=0(FG)ç”¨åŸå›¾ï¼ŒMask=1(BG)ç”¨å™ªå£°
    hybrid_init_np = b * (1.0 - mask_broadcast) + noise_np * mask_broadcast
    
    # å˜é‡
    raw_image_var = tf.Variable(hybrid_init_np, trainable=True, dtype=tf.float32)
    input_var = tf.clip_by_value(raw_image_var, 0.0, 255.0)

    model.build(input_var)
    
    # ä¼šè¯é…ç½®
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    
    # ================= è®­ç»ƒè¿‡ç¨‹ =================
    with tf.Session(config=config) as sess:
        layers = [model.conv1_1, model.conv2_1, model.conv3_1, model.conv4_1, model.conv5_1]

        # è®¡ç®— Targets
        target_grams_fg = []
        style_fg_val = sess.run(style_fg_resized)
        sess.run(raw_image_var.assign(style_fg_val.reshape(1, img_width, img_height, 3)))
        for layer in layers:
            target_grams_fg.append(sess.run(compute_global_gram(layer)))

        target_grams_bg = []
        style_bg_val = sess.run(style_bg_resized)
        sess.run(raw_image_var.assign(style_bg_val.reshape(1, img_width, img_height, 3)))
        for layer in layers:
            target_grams_bg.append(sess.run(compute_global_gram(layer)))
        
        # æ¢å¤Contentè®¡ç®—Content Loss Target
        sess.run(raw_image_var.assign(b))
        
        # --- Loss æ„å»º ---
        # 1. Style Loss (åˆ†å±‚è®¡ç®—)
        style_losses = []
        for i, layer in enumerate(layers):
            h, w = int(layer.shape[1]), int(layer.shape[2])
            m_bg_l = tf.image.resize_nearest_neighbor(mask_bg, [h, w])
            m_fg_l = tf.image.resize_nearest_neighbor(mask_fg, [h, w])
            
            # FG
            gram_fg = compute_masked_gram(layer, m_fg_l)
            loss_fg = tf.reduce_sum(tf.square(gram_fg - target_grams_fg[i]))
            
            # BG
            gram_bg = compute_masked_gram(layer, m_bg_l)
            loss_bg = tf.reduce_sum(tf.square(gram_bg - target_grams_bg[i]))
            
            layer_loss = (FG_STYLE_RATIO * loss_fg + BG_STYLE_RATIO * loss_bg) * STYLE_LAYER_WEIGHTS[i]
            style_losses.append(layer_loss)
            
        style_loss = sum(style_losses) / 5.0

        # 2. Content Loss
        def weighted_content_loss(layer, target):
            h, w = int(layer.shape[1]), int(layer.shape[2])
            sw = tf.image.resize_nearest_neighbor(mask_fg, [h, w])*1.0 + \
                 tf.image.resize_nearest_neighbor(mask_bg, [h, w])*BG_CONTENT_WEIGHT
            diff = tf.square(layer - target) * sw
            return tf.reduce_sum(diff) / (2.0 * np.sqrt(h * w * int(layer.shape[3])))

        t_c42 = sess.run(model.conv4_2, feed_dict={input_var: b})
        t_c12 = sess.run(model.conv1_2, feed_dict={input_var: b})
        content_loss = (weighted_content_loss(model.conv4_2, t_c42) + 
                        weighted_content_loss(model.conv1_2, t_c12)) / 2.0

        # 3. Laplace Loss
        laplace_loss = 0.0
        lap_spatial_weight = mask_fg * 1.0 + mask_bg * BG_LAPLACE_WEIGHT 
        for p_size in [1, 2, 4, 8, 10, 16]:
            if p_size == 1:
                p_in = input_var
            else:
                p_in = tf.nn.pool(input_var, window_shape=[p_size, p_size], pooling_type='AVG', padding='SAME', strides=[p_size, p_size])
                p_in = tf.nn.pool(input_var, window_shape=[p_size, p_size], pooling_type='AVG', padding='SAME', strides=[p_size, p_size])
            
            t_shape = tf.shape(p_in)[1:3]
            c_weight = tf.image.resize_nearest_neighbor(lap_spatial_weight, t_shape)
            
            lap_op = laplace(p_in)
            t_lap = sess.run(lap_op, feed_dict={raw_image_var: b})
            
            weighted_diff = tf.square(lap_op - t_lap) * c_weight
            laplace_loss += tf.reduce_mean(weighted_diff)

        # 4. Total Loss & Opt
        coefs = [1e7, 1e5, 1e10] # Style, Content, Laplace
        total_loss = coefs[0]*style_loss + coefs[1]*content_loss + coefs[2]*laplace_loss
        
        train_op = tf.contrib.opt.ScipyOptimizerInterface(total_loss, method='L-BFGS-B', options={'maxiter': 1000})
        
        # åˆå§‹åŒ–
        sess.run(tf.global_variables_initializer())
        print(f"[{style_name_no_ext}] åº”ç”¨æ··åˆåˆå§‹åŒ–...")
        sess.run(raw_image_var.assign(hybrid_init_np))

        # å›è°ƒå‡½æ•°
        # ä¸ºäº†ä¸è®©æ‰“å°å¤ªä¹±ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„è®¡æ•°å™¨ç±»
        class StepCounter:
            def __init__(self):
                self.step = 0
        
        counter = StepCounter()

        def callback(tl, cl, sl, ll, ii):
            if counter.step % 100 == 0:
                print(f"[{style_name_no_ext}] Iter: {counter.step:4d} | Total: {tl:.2e}")
                # ä¿å­˜ä¸­é—´ç»“æœåˆ°å¯¹åº”å­æ–‡ä»¶å¤¹
                img_save = PIL.Image.fromarray(tf.cast(ii, dtype=tf.uint8).eval(session=sess)[0], 'RGB')
                save_name = os.path.join(current_output_dir, f"iter_{counter.step}.png")
                img_save.save(save_name)
            counter.step += 1

        train_op.minimize(sess, 
                          fetches=[total_loss, content_loss, style_loss, laplace_loss, input_var], 
                          loss_callback=callback)

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_img = PIL.Image.fromarray(input_var.eval(session=sess)[0], 'RGB')
        final_save_path = os.path.join(current_output_dir, "final_result.png")
        final_img.save(final_save_path)
        print(f"âœ… [{style_name_no_ext}] å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ {final_save_path}")

# ==========================================
# ä¸»ç¨‹åºå…¥å£ï¼šå¾ªç¯æ‰§è¡Œ
# ==========================================
if __name__ == "__main__":
    print(f"å¼€å§‹æ‰¹é‡å¤„ç†ï¼Œå…± {len(STYLE_IMAGES_LIST)} å¼ é£æ ¼å›¾...")
    
    for style_file in STYLE_IMAGES_LIST:
        run_style_transfer(style_file)
        
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼è¯·æ£€æŸ¥ data/batch_results_dual æ–‡ä»¶å¤¹ã€‚")